{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QAsubsystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ShAfpLSAJMP",
        "outputId": "5480a194-e006-483e-f94d-51a11644c578"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta1V5KhQ1fOi",
        "outputId": "ca09d5b7-94a8-47ff-f140-cf64a7d30501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/QAsubsystem\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive._mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/QAsubsystem')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install virtualenv\n",
        "\n",
        "#!virtualenv QAenv"
      ],
      "metadata": {
        "id": "9gYN1dghAnhx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip; pip install git+https://github.com/deepset-ai/haystack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4wJ58cBlCM",
        "outputId": "861fe3e0-e1b2-4042-d4f7-de04e0c091e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/deepset-ai/haystack.git\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-req-build-eown62qg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-req-build-eown62qg\n",
            "  Resolved https://github.com/deepset-ai/haystack.git to commit a26c0429941b2c528406bac130483937f0dba50d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (0.3.5.1)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.4.9)\n",
            "Requirement already satisfied: elasticsearch<=7.10,>=7.7 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (7.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (4.64.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (2.2.0)\n",
            "Requirement already satisfied: transformers==4.19.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (4.19.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.2.2)\n",
            "Requirement already satisfied: azure-core<1.23 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.22.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.0.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (4.3.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (0.8.11)\n",
            "Requirement already satisfied: torch<1.12,>1.9 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.4.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.0.9)\n",
            "Requirement already satisfied: mmh3 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (3.0.0)\n",
            "Requirement already satisfied: elastic-apm in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (6.9.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (2.0.11)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (4.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (3.7)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.26.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.9.1)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (0.7.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.3.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (2.6.3)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (1.24)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (8.13.0)\n",
            "Requirement already satisfied: azure-ai-formrecognizer==3.2.0b2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.5.1rc0) (3.2.0b2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.5.1rc0) (1.15.0)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.7/dist-packages (from azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.5.1rc0) (1.1.28)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.7/dist-packages (from azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.5.1rc0) (0.6.21)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->farm-haystack==1.5.1rc0) (0.12.1)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.5.1rc0) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.5.1rc0) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.5.1rc0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.5.1rc0) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack==1.5.1rc0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack==1.5.1rc0) (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=2.2.0->farm-haystack==1.5.1rc0) (0.12.0+cu113)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=2.2.0->farm-haystack==1.5.1rc0) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.12,>1.9->farm-haystack==1.5.1rc0) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->farm-haystack==1.5.1rc0) (3.8.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack==1.5.1rc0) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack==1.5.1rc0) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack==1.5.1rc0) (5.7.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (3.17.3)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (1.8.0)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (5.0.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (1.4.37)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (1.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (7.1.2)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (0.16.8)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (1.2.4)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (3.1.27)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (20.1.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (2022.1)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (0.4.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (1.1.4)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow->farm-haystack==1.5.1rc0) (0.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack==1.5.1rc0) (2.8.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from posthog->farm-haystack==1.5.1rc0) (1.6)\n",
            "Requirement already satisfied: backoff<2.0.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from posthog->farm-haystack==1.5.1rc0) (1.11.1)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->farm-haystack==1.5.1rc0) (4.2.6)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from quantulum3->farm-haystack==1.5.1rc0) (2.1.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (from quantulum3->farm-haystack==1.5.1rc0) (0.5.10)\n",
            "Requirement already satisfied: jarowinkler<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from rapidfuzz->farm-haystack==1.5.1rc0) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika->farm-haystack==1.5.1rc0) (57.4.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->farm-haystack==1.5.1rc0) (2.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->farm-haystack==1.5.1rc0) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->farm-haystack==1.5.1rc0) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow->farm-haystack==1.5.1rc0) (1.3.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow->farm-haystack==1.5.1rc0) (4.0.9)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.5.1rc0) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.5.1rc0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.2->farm-haystack==1.5.1rc0) (3.0.9)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow->farm-haystack==1.5.1rc0) (1.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->farm-haystack==1.5.1rc0) (1.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->farm-haystack==1.5.1rc0) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->farm-haystack==1.5.1rc0) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->farm-haystack==1.5.1rc0) (1.0.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->quantulum3->farm-haystack==1.5.1rc0) (0.6.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->farm-haystack==1.5.1rc0) (0.14.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=2.2.0->farm-haystack==1.5.1rc0) (7.1.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->farm-haystack==1.5.1rc0) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow->farm-haystack==1.5.1rc0) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8kjqiRFINIYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# haystack class module\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from haystack.nodes import TextConverter\n",
        "from haystack.nodes import PreProcessor\n",
        "from haystack.document_stores import ElasticsearchDocumentStore, InMemoryDocumentStore\n",
        "from haystack.nodes import FARMReader, BM25Retriever\n",
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "class QuestionAnsweringSystem():\n",
        "\n",
        "  def __init__(self, data_dir, train_filename):\n",
        "      \n",
        "      self.data_dir = data_dir\n",
        "      self.train_filename = train_filename\n",
        "\n",
        "  def convert_to_haystack_format(self) -> List:\n",
        "    \n",
        "    # convert txt files to dicts\n",
        "    all_docs = []\n",
        "    converter = TextConverter(valid_languages=[\"el\"])\n",
        "    for file in Path(self.data_dir).iterdir():\n",
        "        all_docs.append(converter.convert(file_path=file, meta=None)[0])\n",
        "    # clean and split\n",
        "    preprocessor = PreProcessor(\n",
        "        language='el',\n",
        "        clean_empty_lines=True,\n",
        "        clean_whitespace=True,\n",
        "        clean_header_footer=False,\n",
        "        split_by=\"word\",\n",
        "        split_length=200,\n",
        "        split_respect_sentence_boundary=True,\n",
        "    )\n",
        "    docs = preprocessor.process(all_docs)\n",
        "    return docs\n",
        "  \n",
        "  def create_document_store(self, docs, similarity_metric='cosine_similarity'):\n",
        "    document_store = InMemoryDocumentStore(similarity_metric)\n",
        "    try:\n",
        "      document_store.write_documents(docs)\n",
        "      return document_store\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  def fine_tune_reader_model (self, reader_model_path, n_epochs, model=\"deepset/xlm-roberta-large-squad2\", use_gpu=True):\n",
        "\n",
        "      reader = FARMReader(model_name_or_path=model, use_gpu=use_gpu)\n",
        "      try:\n",
        "\n",
        "        reader.train(\n",
        "            data_dir = self.data_dir,\n",
        "            train_filename=self.train_filename,\n",
        "            use_gpu=use_gpu,\n",
        "            n_epochs=n_epochs,\n",
        "            save_dir = reader_model_path)\n",
        "        print ('fine-tuning done')\n",
        "      except Exception as e:\n",
        "        print (e)\n",
        "\n",
        "  def get_retriever(self, document_store):\n",
        "    return BM25Retriever(document_store)\n",
        "  def get_reader(self, reader_model_path):\n",
        "    return FARMReader(model_name_or_path=reader_model_path)\n",
        "  def get_pipeline (self, reader, retriever):\n",
        "    return ExtractiveQAPipeline(reader, retriever)\n",
        "  def get_answers (seld, query, pipeline, top_k_retriever=10, top_k_reader = 3):\n",
        "    predictions = pipeline.run(\n",
        "      query=query, params={\"Retriever\": {\"top_k\": top_k_retriever}, \"Reader\": {\"top_k\": top_k_reader}}\n",
        "      )\n",
        "    return [{'answer': result['answer'], 'context': result['context'], 'startLoc': result['offset_start_in_doc'], 'endLoc': result['offset_end_in_doc'], 'docText':  self.get_haystack_doc_text_by_id(document_store, result['document_id']), 'probability': result['probability']} for\n",
        "                result in predictions['answers']]\n",
        "\n"
      ],
      "metadata": {
        "id": "QJH6Zi2q7S66"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main module\n",
        "import os\n",
        "\n",
        "#if name == _main_:\n",
        "DATA_DIR = 'data/first_model_data'\n",
        "TRAIN_FILE = 'answers.json'\n",
        "MODEL_PATH = './models'\n",
        "\n",
        "if os.path.isdir(MODEL_PATH) == False:\n",
        "    os.mkdir(MODEL_PATH)\n",
        "\n",
        "# initialize class\n",
        "qa_system = QuestionAnsweringSystem(DATA_DIR, TRAIN_FILE)\n",
        "\n",
        "# get documents\n",
        "docs =  qa_system.convert_to_haystack_format()\n",
        "print (\"pre-processing done\")\n",
        "\n",
        "# document store\n",
        "ds = qa_system.create_document_store(docs)\n",
        "print ('created document store')\n",
        "\n",
        "# fine-tune model on data\n",
        "qa_system.fine_tune_reader_model (MODEL_PATH,n_epochs=1)\n",
        "print ('fine-tuning done')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "93rL3ZXrORs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe592266-fd01-4ed6-8cc9-79db73d2c58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/17 [00:00<?, ?docs/s]WARNING - haystack.nodes.preprocessor.preprocessor -  One or more sentence found with word count higher than the split length.\n",
            "100%|██████████| 17/17 [00:00<00:00, 269.30docs/s]\n",
            "INFO - haystack.modeling.utils -  Using devices: CPU\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id '990b8e07a4738a0a23c3ed50e967f99f' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id 'ec49a131d59306ca7d0c7bf19cc22477' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id 'c54aaee15abcc34f1adf035dcafcccca' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id '4307f9bb7e4d905eb712a8c277c606bf' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id '263c4f3445a66fe256ace27bf44b1e5' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id 'be79f7be8695d941316b8e91b016488f' already exists in index 'cosine_similarity'\n",
            "INFO - haystack.modeling.utils -  Using devices: CPU\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
            "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
            "INFO - haystack.modeling.model.language_model -  =============\n",
            "INFO - haystack.modeling.model.language_model -  Could not find deepset/xlm-roberta-large-squad2 locally.\n",
            "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
            "INFO - haystack.modeling.model.language_model -  Loaded deepset/xlm-roberta-large-squad2\n",
            "INFO - haystack.modeling.utils -  Using devices: CPU\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
            "INFO - haystack.modeling.infer -  Got ya 2 parallel workers to do inference ...\n",
            "INFO - haystack.modeling.infer -   0     0  \n",
            "INFO - haystack.modeling.infer -  /w\\   /w\\ \n",
            "INFO - haystack.modeling.infer -  /'\\   / \\ \n",
            "INFO - haystack.modeling.utils -  Using devices: CPU\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
            "INFO - haystack.modeling.data_handler.data_silo -  \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "INFO - haystack.modeling.data_handler.data_silo -  LOADING TRAIN DATA\n",
            "INFO - haystack.modeling.data_handler.data_silo -  ==================\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Loading train set from: data/first_model_data/answers.json \n",
            "INFO - haystack.modeling.data_handler.data_silo -  Multiprocessing disabled, using a single worker to convert 14dictionaries to pytorch datasets.\n",
            "Preprocessing Dataset data/first_model_data/answers.json: 100%|██████████| 14/14 [00:00<00:00, 61.05 Dicts/s] \n",
            "INFO - haystack.modeling.data_handler.data_silo -  \n",
            "INFO - haystack.modeling.data_handler.data_silo -  LOADING DEV DATA\n",
            "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
            "INFO - haystack.modeling.data_handler.data_silo -  No dev set is being loaded\n",
            "INFO - haystack.modeling.data_handler.data_silo -  \n",
            "INFO - haystack.modeling.data_handler.data_silo -  LOADING TEST DATA\n",
            "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
            "INFO - haystack.modeling.data_handler.data_silo -  No test set is being loaded\n",
            "INFO - haystack.modeling.data_handler.data_silo -  \n",
            "INFO - haystack.modeling.data_handler.data_silo -  DATASETS SUMMARY\n",
            "INFO - haystack.modeling.data_handler.data_silo -  ================\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Examples in train: 194\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Examples in dev  : 0\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Examples in test : 0\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Total examples   : 194\n",
            "INFO - haystack.modeling.data_handler.data_silo -  \n",
            "INFO - haystack.modeling.data_handler.data_silo -  Longest sequence length observed after clipping:     256\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Average sequence length after clipping: 247.8556701030928\n",
            "INFO - haystack.modeling.data_handler.data_silo -  Proportion clipped:      0.845360824742268\n",
            "INFO - haystack.modeling.data_handler.data_silo -  [Haystack Tip] 84.5% of your samples got cut down to 256 tokens. Consider increasing max_seq_len. This will lead to higher memory consumption but is likely to improve your model performance\n",
            "INFO - haystack.modeling.model.optimization -  Loading optimizer `AdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "INFO - haystack.modeling.model.optimization -  Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO - haystack.modeling.model.optimization -  Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 20, 'num_warmup_steps': 4}'\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000):   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever & reader\n",
        "retriever = qa_system.get_retriever(ds)\n",
        "reader = qa_system.get_reader(MODEL_PATH)\n",
        "\n",
        "# pipeline \n",
        "pipe = qa_system.get_pipeline(reader, retriever)\n",
        "\n",
        "# get answers dictionary\n",
        "\n",
        "answers  = qa_system.get_answers(\"Μπορώ να κάνω δεύτερη δόση με διαφορετικό εμβόλιο;\",pipe)\n",
        "print(answers)\n"
      ],
      "metadata": {
        "id": "0l5cuo_58guR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}